{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) Evaluating the performance of the rule-base name generator.\n",
    "#\n",
    "# Please go through the step_2 and step_3 notebooks before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILEPATH = \"../Data/names.txt\"\n",
    "bound_character = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albonsha',\n",
       " 'beenapreethi',\n",
       " 'thushniha',\n",
       " 'aakaksha',\n",
       " 'dumeethran',\n",
       " 'luhit',\n",
       " 'valam',\n",
       " 'harinyai',\n",
       " 'sakthikaa',\n",
       " 'kaveetha']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the names from the dataset and create a list of names.\n",
    "with open(DATASET_FILEPATH, \"r\") as f:\n",
    "    names = [name.strip() for name in f.readlines()]\n",
    "\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY PASTE THE CODE FROM `step_2_rule_based_name_generator.py` THAT CALCULATES THE PROBABILITIES.\n",
    "char_to_int = {char: idx + 1 for idx, char in enumerate(string.ascii_lowercase)}\n",
    "char_to_int[bound_character] = 0\n",
    "int_to_char = {idx: char for char, idx in char_to_int.items()}\n",
    "char_counts = torch.zeros(size=(27, 27), dtype=torch.int32)\n",
    "\n",
    "for name in names:\n",
    "    name = bound_character + name + bound_character\n",
    "    for first_character, second_character in zip(name, name[1:]):\n",
    "        first_character_idx = char_to_int[first_character]\n",
    "        second_character_idx = char_to_int[second_character]\n",
    "        char_counts[first_character_idx][second_character_idx] += 1\n",
    "\n",
    "char_counts += 1\n",
    "char_probs = char_counts / char_counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized loss: 2.207580327987671\n"
     ]
    }
   ],
   "source": [
    "# Now, let's calculate the loss associated with this model which is also the quality of the name generator.\n",
    "loss = 0.0\n",
    "num_data_points = 0\n",
    "for name in names:\n",
    "    num_data_points += len(name) + 1\n",
    "    name = bound_character + name + bound_character\n",
    "    for first_character, second_character in zip(name, name[1:]):\n",
    "        first_character_idx = char_to_int[first_character]\n",
    "        second_character_idx = char_to_int[second_character]\n",
    "        loss += -torch.log(char_probs[first_character_idx][second_character_idx])\n",
    "\n",
    "normalized_loss = loss / num_data_points\n",
    "print(f\"Normalized loss: {normalized_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".makemore_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
